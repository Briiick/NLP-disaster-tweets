{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f681b0b5-d943-4a48-8af4-cd784664a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add keyword to end of text for train and test data\n",
    "keyword_list_train = list(clean_train_data['keyword'])\n",
    "keyword_list_test = list(clean_test_data['keyword'])\n",
    "key_list_train = ['' if (type(i) == float and np.isnan(i)) else i for i in keyword_list_train]\n",
    "key_list_test = ['' if (type(i) == float and np.isnan(i)) else i for i in keyword_list_test]\n",
    "text_list_train = list(clean_train_data['text'])\n",
    "text_list_test = list(clean_test_data['text'])\n",
    "\n",
    "# iterate through and add to end, with space in-between\n",
    "for i in range(len(clean_train_data['keyword'])):\n",
    "    text_list_train[i] = text_list_train[i] + ' ' + key_list_train[i]\n",
    "\n",
    "for i in range(len(clean_test_data['keyword'])):\n",
    "    text_list_test[i] = text_list_test[i] + ' ' + key_list_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "573e8521-e5d3-4a3b-9d86-a8eee9ae7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabel text\n",
    "clean_train_data['text'] = text_list_train\n",
    "clean_test_data['text'] = text_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0bb2d7e7-be5e-4486-b5ec-7ecb3de7e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop keyword col\n",
    "clean_train_data = clean_train_data.drop(columns='keyword')\n",
    "clean_test_data = clean_test_data.drop(columns='keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "05b0342d-a149-4e19-acad-a4c29111bcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4            Forest fire near La Ronge Sask. Canada        1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output as check\n",
    "clean_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8e172ecf-6864-4e1d-adc3-b1b7edb6f557",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TFSequenceClassifierOutput' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-c22a378bcbff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this checks if the probability of disaster is above 0.5. If so, we label 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_pred_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtest_pred_bool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TFSequenceClassifierOutput' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "# this checks if the probability of disaster is above 0.5. If so, we label 1.\n",
    "test_pred_bool = test_pred.copy().astype(int)\n",
    "for index in range(len(test_pred)): \n",
    "    if test_pred[index]>0.5:\n",
    "        test_pred_bool[index]=1\n",
    "    else:\n",
    "        test_pred_bool[index]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9f868-c3c0-43e9-9bbe-14674039864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = test_pred_bool.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01220576-cd88-4b4f-97dd-66cfe4855a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, final_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b38b5-3332-4303-86d8-ce2786e95557",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5543fe7-071a-4ba5-9d88-8472b7a21c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetClassifier(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        \n",
    "        super(TweetClassifier, self).__init__(name=name)\n",
    "        \n",
    "        bias_initializer = tf.keras.initializers.HeNormal()\n",
    "        \n",
    "        self.embedding = Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.pool = GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = Dropout(rate=dropout_rate)\n",
    "\n",
    "        self.last_dense = Dense(units=1, activation=\"sigmoid\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3) \n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7bd4cf7-ff5b-4448-b892-311aa893f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 2\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d37a29d-7031-4887-9a58-afdffdbb5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TweetClassifier(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8cb4e2d-bbfa-4904-9246-84ebbdbb96ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "53/53 [==============================] - 5s 75ms/step - loss: 0.0000e+00 - accuracy: 0.5665 - val_loss: 0.0000e+00 - val_accuracy: 0.5793\n",
      "Epoch 2/5\n",
      "53/53 [==============================] - 4s 77ms/step - loss: 0.0000e+00 - accuracy: 0.5671 - val_loss: 0.0000e+00 - val_accuracy: 0.5793\n",
      "Epoch 3/5\n",
      "53/53 [==============================] - 4s 76ms/step - loss: 0.0000e+00 - accuracy: 0.5670 - val_loss: 0.0000e+00 - val_accuracy: 0.5793\n",
      "Epoch 4/5\n",
      "53/53 [==============================] - 4s 81ms/step - loss: 0.0000e+00 - accuracy: 0.5688 - val_loss: 0.0000e+00 - val_accuracy: 0.5793\n",
      "Epoch 5/5\n",
      "53/53 [==============================] - 4s 85ms/step - loss: 0.0000e+00 - accuracy: 0.5579 - val_loss: 0.0000e+00 - val_accuracy: 0.5793\n",
      "Model: \"text_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  6104400   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            multiple                  40100     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            multiple                  60100     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            multiple                  80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  77056     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  257       \n",
      "=================================================================\n",
      "Total params: 6,362,013\n",
      "Trainable params: 6,362,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = text_model.fit(X_train, y_train, epochs=NB_EPOCHS, batch_size=100, validation_data=(X_test, y_test))\n",
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be181cf3-e5e0-47f4-ab4c-a9ef340bb653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 660us/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "[0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "results = text_model.evaluate(X_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81763df5-ec85-4387-8de8-5cdb6f79f579",
   "metadata": {},
   "source": [
    "#### BERT Modelling first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cd699058-2690-42ca-90a1-db3b1bbb626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1', trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f50a3418-9c6f-451f-9551-4a3005887ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_seq_len, lr):\n",
    "        \n",
    "    input_word_ids = Input(shape=(max_seq_len,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_mask = Input(shape=(max_seq_len,), dtype=tf.int32, name='input_mask')\n",
    "    segment_ids = Input(shape=(max_seq_len,), dtype=tf.int32, name='segment_ids')    \n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])   \n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(clf_output)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    optimizer = SGD(learning_rate=lr, momentum=0.8)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c4aa7-9602-4955-a7d8-86cf5ac9cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "all_masks = []\n",
    "all_segments = []\n",
    "\n",
    "for text in texts:\n",
    "    text = self.tokenizer.tokenize(text)\n",
    "    text = text[:self.max_seq_length - 2]\n",
    "    input_sequence = ['[CLS]'] + text + ['[SEP]']\n",
    "    pad_len = self.max_seq_length - len(input_sequence)\n",
    "\n",
    "    tokens = self.tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "    tokens += [0] * pad_len\n",
    "    pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "    segment_ids = [0] * self.max_seq_length\n",
    "\n",
    "    all_tokens.append(tokens)\n",
    "    all_masks.append(pad_masks)\n",
    "    all_segments.append(segment_ids)\n",
    "\n",
    "return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa659b9-1007-4272-bfe8-062dafdb2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_encoded = self.encode(X.loc[trn_idx, 'text_cleaned'].str.lower())\n",
    "y_trn = X.loc[trn_idx, 'target_relabeled']\n",
    "X_val_encoded = self.encode(X.loc[val_idx, 'text_cleaned'].str.lower())\n",
    "y_val = X.loc[val_idx, 'target_relabeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1e146f17-e7b2-49d5-9a28-ebf58007be9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_trn_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-691124f047f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trn_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_trn_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = build_model(bert_layer, max_seq_len=128, lr=0.0001)        \n",
    "model.fit(X_trn_encoded, y_trn, validation_data=(X_val_encoded, y_val), callbacks=[metrics], epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fcd8a0f6-9a3a-440c-9ba9-1509b9b42f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * ['this is such an amazing movie!']\n    * False\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')}\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask')}\n    * False\n    * None\n  Keyword arguments: {}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-a75b93250f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'this is such an amazing movie!'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_preprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Keys       : {list(text_preprocessed.keys())}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Shape      : {text_preprocessed[\"input_word_ids\"].shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Behave like BatchNormalization. (Dropout is different, b/181839368.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m       result = smart_cond.smart_cond(training,\n\u001b[0m\u001b[1;32m    238\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                                      lambda: f(training=False))\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m       result = smart_cond.smart_cond(training,\n\u001b[1;32m    238\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                                      lambda: f(training=False))\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;31m# Unwrap dicts returned by signatures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pygen/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m           \u001b[0;34m\"Option {}:\\n  {}\\n  Keyword arguments: {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           .format(index + 1, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 267\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;34m\"Could not find matching function to call loaded from the SavedModel. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;34m\"Got:\\n  {}\\n  Keyword arguments: {}\\n\\nExpected \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * ['this is such an amazing movie!']\n    * False\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')}\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask')}\n    * False\n    * None\n  Keyword arguments: {}"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_layer(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28f775-2ac8-4db9-805c-13a40f546f1b",
   "metadata": {},
   "source": [
    "#### Additional Machine Learning Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2e0571a3-6a0c-488e-86b5-5cbff77798d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing a support vector machine\n",
    "\n",
    "# because I haven't done any NLP, I will just use random data with my labels.\n",
    "\n",
    "y_true = clean_train_data['target']\n",
    "x1 = np.random.random_sample(len(y_true))\n",
    "x2 = np.random.random_sample(len(y_true))\n",
    "xs = list(zip(x1,x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "183731a4-e5eb-4d6c-8421-ff0693fbf83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xs, y_true, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f9855ad6-4a6a-4cd8-b9eb-9633fcd09d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(probability=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d3012bf6-29d1-49c8-a189-6a96fe38cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_probas = clf.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
